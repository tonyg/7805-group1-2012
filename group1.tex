\documentclass[english]{article}
\usepackage{mathpazo}
\usepackage{helvet}
\usepackage{courier}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper]{geometry}
\geometry{verbose,tmargin=3cm,bmargin=4cm,lmargin=3cm,rmargin=3cm}
\usepackage{amsthm}
\usepackage{amsmath}

\makeatletter
\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\theoremstyle{plain}
\newtheorem{lem}[thm]{Lemma}
\makeatother

\usepackage{babel}

%%\setlength{\parindent}{0pt}
%%\setlength{\parskip}{2ex}

\begin{document}

\title{7805 Class project, 2012: Group 1}
\author{
  Tony Garnock-Jones,
  Zahra Jafargholi,
  Ravishankar Rajagopal,\\
  Bochao Shen,
  Saber Shokat Fadaee,
%%  Triết Võ Hữu -- I tried to get inputenc to accept this but it wouldn't
  Triet Vo Huu
}
\maketitle

\section{Overview}

We show that any function computable in time $T(n)$ on a
nondeterministic random-access Turing machine (RTM) is computable in
time $T(n)(\log T(n))^{O(1)}$ on a $k$-tape nondeterministic
non-random-access Turing machine.\footnote{$T(n)(\log T(n))^{O(1)}$
  doesn't quite line up with the definition of efficient simulation
  below! It's stricter; can we actually achieve this stricter bound?
  Or should we relax our goal to be polylog-overhead, as per the
  definition of efficient simulation?}
The core idea is to efficiently simulate some machine model that
allows random access using a model lacking random access.

\begin{defn}
  %% Verbatim text retyped from Gurevich:
  %%
  %% ``... one often checks that any T(n)-time-bounded machine of one
  %% kind can be simulated by some machine of the other kind in time
  %% T(n)h(n) where the overhead h(n) is bounded by a polynomial of
  %% T(n) or even n. ... It is often the case that the overhead h(n)
  %% is bounded by polynomial of the logarithm of T(n); let us call
  %% such simulations efficient.''

  (Efficient simulation, after \cite{DBLP:conf/ershov/GurevichS89}.) A
  machine of some kind that is $T(n)$-time-bounded is said to be
  \emph{efficiently simulated} by some machine of another kind when
  the simulating machine is time-bounded by a polynomial of $\log
  T(n)$; that is, when the overhead of simulation is bounded by a
  polylog function of $n$.
\end{defn}

Although we start from a specific machine, RTM (defined formally
below), it is shown in \cite{DBLP:conf/ershov/GurevichS89} that a
number of variants, namely RAC (Random Access Computer), Kolmogorov
machines and Sch\"{o}nhage machines, all efficiently simulate each
other and therefore share the same notion of $n^{O(1)}$ computability.

We first define the notion of a non-deterministic RTM. We then define
a variant of RTM called a frugal RTM, and show that every specific RTM
can be efficiently simulated by some frugal RTM. Finally, we show how
any computation using a \emph{non-deterministic} frugal RTM can be
efficiently simulated on a $k$-tape non-deterministic Turing machine,
where $k>1$. In order to accomplish this, we prove and make use of the
fact that a non-deterministic Turing machine can sort in time $n \log
n$, where $n$ is the length of the input.

\section{From RTMs to Frugal RTMs}

\begin{defn}
  (Random-access Turing Machine, RTM.) We use verbatim\footnote{There
    are a couple of typos in Gurevich's paper; we have corrected them
    in the presentation here.} the definition from
  \cite{DBLP:conf/ershov/GurevichS89}:

  \begin{quote}
    An RTM is a Turing machine with three linear tapes called the
    \emph{main tape}, the \emph{address tape} and the \emph{auxiliary
      tape}, such that the head of the main tape (the \emph{main
      head}) is always on the cell whose number is the contents of the
    address tape. An instruction for an RTM has the form
    \begin{equation*}
      (p,\alpha_1,\alpha_2,\alpha_3) \rightarrow
      (q,\beta_1,\beta_2,\beta_3,\gamma_1,\gamma_2)
    \end{equation*}
    and means the following: If the control state is $p$ and the
    symbols in the observed cells on the three tapes are binary digits
    $\alpha_1,\alpha_2,\alpha_3$ respectively, then print binary
    digits $\beta_1,\beta_2,\beta_3$ in the respective cells, move the
    address head to the left (resp. to the right) if $\gamma_1=-1$
    (resp. $\gamma_1=1$), move the auxiliary-tape head with respect
    to $\gamma_2$ and go to control state $q$.
  \end{quote}
\end{defn}

\begin{defn}
  (Frugal RTM.) An RTM is called \emph{frugal} if at any time $t$, the
  lengths of the address tape and of the auxiliary tape are both
  bounded by $O(\log t)$.
\end{defn}

\begin{thm}
  Frugal RTMs can efficiently simulate RTMs.
\end{thm}

\begin{proof}
  ((I'll write this up ---tonyg))
\end{proof}

\section{From Nondeterministic Frugal RTMs to Nondeterministic Multi-tape TMs}

Simulating a computation on a frugal RTM using a multi-tape TM is
carried out by non-deterministically guessing the sequence of steps on
the computation and then checking for the correctness of the
sequence. However in order to do the latter, we need multi-tape TMs to
be able to sort efficiently.

\begin{lem}
  Let $\ell$ be a list of natural numbers of length $|\ell|$ numbers,
  and let $C(\ell)$ be an encoding of $\ell$, of length $|C(\ell)|$
  symbols. Then, $\ell$ can be sorted by a nondeterministic multi-tape
  Turing machine in time $O(|C(\ell)|\log|\ell|)$.
\end{lem}

\begin{proof}
  In the following let $[n] = \{1,2,\ldots n\}$. Let $\ell = (l_i \in
  N: i \in [m])$ be a list (sequence) of natural numbers $(l_1,l_2,
  \ldots l_m)$. Then the encoding $C(\ell)$ $\in \Sigma^*$ is defined
  as
\[
C(\ell) = c(l_1) \# c(l_2) \# \ldots c(l_m) \#
\]
  where $\Sigma$, the input alphabet to our sorting machine, is the
  set including $0$ and $1$ as well as the pound symbol ($\#$), and
  $c(v)$ is the binary representation of $v \in \mathbb{N}$. For
  example, $C((1,2,13))=1\#10\#1101\#$.

  We define $\Gamma$, our tape alphabet, to be $\Sigma$ with the
  addition of the symbol comma ($,$). We proceed using an algorithm
  based on merge sort, where we repeatedly merge adjacent sorted
  sublists until just one list remains. At the $i$th iteration over
  the input, the sublists we consider have length $2^{i-1}$.

  We choose to use three tapes: the first, main, tape holds the input
  and the partial outputs at each iteration, and the second and third
  tapes are used as working space to hold the sublists to be merged. \\

  The operation of the machine in each iteration is as follows:

  \begin{enumerate}
    \item \label{iteration-start} Return the heads to the beginnings
      of the tapes.
    \item \label{process-sublist} If we are at the end of the main
      tape, then
      \begin{itemize}
        \item if we haven't yet processed any sublists during this
          iteration, the original input was empty. Halt, since an
          empty list is always sorted.
        \item otherwise, go to step \ref{iteration-start}.
      \end{itemize}
    \item Copy symbols from the main tape to the second tape until a
      pound symbol is seen.
    \item If the end of the tape follows the pound symbol we just saw,
      then
      \begin{itemize}
        \item if this was the first sublist we processed during this
          iteration, then we are done: the input has been
          sorted. Halt.
        \item otherwise, we have an odd number of sublists. The final
          iteration of the algorithm will take care of this
          case. Return to step \ref{iteration-start}.
      \end{itemize}
    \item Otherwise, copy symbols from the main tape to the third tape
      until a pound symbol is seen.
    \item Return the heads of the second and third tapes to the
      beginning, and move the head of the main tape back over the two
      sublists just copied to the first symbol of the first sublist of
      the two.
    \item \label{merge-loop} If the symbol on the second tape is the
      pound symbol, place a comma on the main tape and then copy
      symbols from the third tape onto the main tape until we see a
      pound symbol on the third tape also. Place a pound symbol on the
      main tape and go to step \ref{process-sublist}.
    \item Otherwise, if the symbol on the third tape is the pound
      symbol, place a comma on the main tape and then copy symbols
      from the second tape onto the main tape until we see a pound
      symbol on the second tape also. Place a pound symbol on the main
      tape and go to step \ref{process-sublist}.
    \item Otherwise, compare the encodings of the numbers under the
      heads of the second and third tapes. If the smaller is the
      element from the second tape, copy it to the main tape;
      otherwise, copy the element from the third tape. Place a comma
      on the main tape. Rewind whichever of the tapes did not have an
      element copied from it so that its element will be compared
      again next time round. Go to step \ref{merge-loop}.
  \end{enumerate}

  If there are an even number of pound-symbol-delimited sublists in
  the input, then they are of equal length at the start of each
  iteration; and if there are an odd number in the input, then all but
  one will have equal length. To see this, consider that as the
  algorithm begins, all sublists are of length 1, and as it proceeds,
  each pair of length $x$ sublists is replaced by a single length $2x$
  sublist, except for any odd-man-out at the end of the input, which
  will not be processed until the final iteration.

  It remains to be shown that the machine takes time
  $O(|C(\ell)|\log|\ell|)$. We can see that there will be
  $log_2|\ell|$ iterations, since each iteration halves the number of
  remaining sublists until a single sublist remains. Each iteration
  will take $O(|C(\ell)|)$ steps, since every element of the input is
  examined on each iteration, and $O(1)$ steps are needed to perform
  the necessary copyings and comparisons for each element of the
  input. Combining these two observations gives us the required bound.

%% Each comparison process goes as follows: Based on the count of the
%% stages from the fourth tape we copy the first $2^{n-1}$ onto tape two
%% and the next $2^{n-1}$ elements onto tape three. Then we compare the
%% first two elements on the two tapes bit by bit and transfer the
%% minimum element onto the main tape to its corresponding position. The
%% the heads of the second tape and third tape are moved to the least
%% elements on their lists and this process continues.

\end{proof}

((Is this next definition even required?))

\begin{defn}
  (Non-deterministic multi-tape Turing machines.) ((Describe the
  nondeterministic input $y$, and how the pair $(x,y)$ is checked by
  the machine, where the deterministic machine would compute $y$ from
  $x$.))
\end{defn}

We first define the trace of a random access TM computation which
informally is the sequence of states that the machine is in during a
computation.

\begin{defn}
  The trace T of a random-access TM computation is the sequence of tupes
\[
(t,q_t,a_t,I_t,b_t,J_t,c_t): t < T(n)
\]
  such that at time $t$, the TM is in state $q_t$, the address tape
  contents is $a_t$ with the head at $I_t$, the auxiliary tape
  contents is $b_t$ with the head at $J_t$ and the character under the
  head of the main tape is $c_t$.
\end{defn}

\begin{thm}
  $k$-tape nondeterministic TMs can efficiently simulate
  non-deterministic Frugal RTMs.
\end{thm}

\begin{proof}
  Let $M$ be a frugal RTM and$M^{'}$ be the non-deterministic
  mutli-tape TM on which we are going to simulate the computation on
  $M$. The input $x$ is on one if its tapes. $M^{'}$ guesses traces
  for the computation of $M$ on input $x$, guessing tuples in order
  from $t = 0$ to $T(n)$. Since $M$ is frugal each tuple requires
  guessing a $O(polylog T(n))$ amount of information. This is because

  \begin{itemize}
  \item $t$ is a number between $0$ and $T(n)$ and requires $log T(n)$
    bits
  \item $q_t$ has constant size and only depends on $M$
  \item $a_t$ is of size $O(log T(n)$ by definition
  \item $b_t$ is also of size $O(log T(n)$ by definition
  \item $I_t$ is a number representing a location on the address tape
    and therefore also of size $O(log T(n)$
  \item $I_t$ is a number representing a location on the auxiliary tape
    and therefore also of size $O(log T(n)$
  \item $c_t$ has constant size and depends only on the size of the
    alphabet handled by $M$
  \end{itemize}

  $M^{'}$ giess the 6-tuples one by one and checks that the first tuple
  is correct, and every t+1-st tuple is consistent with the t-th one and
  $q_{T(n)}$ is accepting. The notion of consistency is defined as
  follows

  \begin{defn}
    A tuple $(t^{'}, q^{'}, a^{'}, I^{'}, b^{'}, J^{'}, c^{'})$ is
    consistent with the tuple $(t, q, a, I, b, J, c)$ if when in state q
    with address tape a with head at position I, auxiliary tape B with
    head at position J and observing character c on the main tape, $M$
    transitions to state $q^{'}$, updates the address tape to $a^{'}$
    and moves its head to position $I^{'}$, updates the auxiliary tape
    to $b^{'}$ and moves its head to position $J^{'}$.
  \end{defn}

  Note that we \emph{don't} check the $c_{t}$ in each tuple here,
  because of the random-access head movements on the main tape. Once the
  checks here complete, however, we go back and check the $c_{t}$ for
  consistency. To do so,

  \begin{enumerate}
  \item Sort the sequence of tuples first by the contents of the
    address tape, $a_{t}$, and then by time, $t$. (So groups with
    equal $a_{t}$ are formed, and $t$ increases within each group.) By
    lemma 4, we know that this sorting process can be carried out
    efficiently.
  \item For each block (with the same value of $a_{t}$ and increasing
    $t$) we first check if the $c_t$ component of the first tuple is
    the same as the character $M^{'}$ observes under its input
    head. If this is not the case reject.
  \item For two consecutive tuples within the same block, let $c$ be
    the $c_t$ component of the first tuple and $c^{'}$ be the
    corresponding component on the second tuple. Then either of the
    following must be true
    \begin{enumerate}
    \item $c = c{'}$ if the computation corresponding to the first
      tuple did not write any characters onto the main tape
    \item $c <> c{'}$ but the later is equal to the character
      written on the main tape by the computation corresponding to
      the first tuple
    \end{enumerate}
    If either of them is not true, then reject.
  \end{enumerate}

  If each group of tuples is consistent, then the entire computation is
  valid and we accept. Also since this consistency check on the
  characters can be done in time proportional to the length of the
  sorted sequence of tuples, the entire process can be carried out
  efficiently.
\end{proof}

\bibliographystyle{plain}
\bibliography{group1}

\end{document}
